{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-31T10:01:04.192552Z",
     "start_time": "2024-07-31T10:01:00.175317Z"
    }
   },
   "source": [
    "from typing import Optional, TypeVar, Callable, Optional, Tuple\n",
    "from alphagen.data.expression import *\n",
    "\n",
    "from alphagen_qlib.stock_data import StockData\n",
    "from alphagen_generic.features import *\n",
    "\n",
    "import numpy as np\n",
    "from lightgbm import Booster\n",
    "from alphagen.utils.pytorch_utils import normalize_by_day\n",
    "from alphagen.data.calculator import AlphaCalculator\n",
    "from alphagen.utils.correlation import batch_pearsonr, batch_spearmanr\n",
    "\n",
    "_T = TypeVar(\"_T\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T10:01:04.208520Z",
     "start_time": "2024-07-31T10:01:04.194563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_ensemble_alpha(exprs: List[Expression], model: Booster) -> Tensor:\n",
    "    n = len(exprs)\n",
    "    return torch.from_numpy(predict(model, exprs)).to(data.device)\n",
    "\n",
    "def predict(model: Booster, exprs: List[Expression]) -> np.ndarray:\n",
    "    X = torch.stack([_calc_alpha(expr) for expr in exprs], dim=-1).cpu().numpy()\n",
    "    X = X.reshape(-1, X.shape[-1])\n",
    "    val = model.predict(X)\n",
    "    return unstack(val)\n",
    "\n",
    "def unstack(value: np.ndarray) -> np.ndarray:\n",
    "    return value.reshape(data.n_days, data.n_stocks)\n",
    "\n",
    "def _calc_alpha(expr: Expression) -> Tensor:\n",
    "    return normalize_by_day(expr.evaluate(data))\n",
    "\n",
    "def _calc_ICs(value1: Tensor, value2: Tensor) -> Tensor:\n",
    "    return batch_pearsonr(value1, value2)\n",
    "\n",
    "def _calc_IC(value1: Tensor, value2: Tensor) -> float:\n",
    "    return batch_pearsonr(value1, value2).mean().item()\n",
    "\n",
    "def _calc_IR(value1: Tensor, value2: Tensor) -> float:\n",
    "    ICs = _calc_ICs(value1, value2)\n",
    "    IC_mean = ICs.mean().item()\n",
    "    IC_std = ICs.std().item()\n",
    "    epsilon = 1e-10  # 防止除以零的小值\n",
    "    IR = IC_mean / (IC_std - epsilon)\n",
    "    return IR\n",
    "\n",
    "def test_ensemble(exprs: List[Expression], model: Booster, calculator: AlphaCalculator) -> Tuple[float, float]:\n",
    "    return calc_pool_all_ret(exprs, calculator.target_value, model)\n",
    "\n",
    "def calc_pool_all_ret(exprs: List[Expression], target: Tensor, model: Booster) -> Tuple[float, float]:\n",
    "    with torch.no_grad():\n",
    "        ensemble_value = make_ensemble_alpha(exprs, model)\n",
    "        return _calc_IC(ensemble_value, target), _calc_IR(ensemble_value, target)"
   ],
   "id": "dff142a1a34d95ad",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T10:01:34.701168Z",
     "start_time": "2024-07-31T10:01:04.210638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from alphagen_qlib.utils import load_alpha_pool_by_path, load_dt_model_by_path\n",
    "from alphagen_qlib.calculator import QLibStockDataCalculator\n",
    "\n",
    "POOL_PATH = 'model/18432_steps_pool.json'\n",
    "DT_PATH = 'model/18432_steps_dt.txt'\n",
    "\n",
    "data = StockData(instrument='csi500',\n",
    "                 start_time='2016-06-01',\n",
    "                 end_time='2022-06-01')\n",
    "\n",
    "close = Feature(FeatureType.CLOSE)\n",
    "target = Ref(close, -20) / close - 1\n",
    "\n",
    "calculator = QLibStockDataCalculator(data=data, target=target)\n",
    "exprs, _ = load_alpha_pool_by_path(POOL_PATH)\n",
    "booster = load_dt_model_by_path(DT_PATH)\n",
    "\n",
    "ensemble_alpha = make_ensemble_alpha(exprs, booster)\n",
    "df = data.make_dataframe(ensemble_alpha)\n",
    "\n",
    "print(test_ensemble(exprs, booster, calculator))"
   ],
   "id": "107e39e7ead71e3f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[36736:MainThread](2024-07-31 18:01:04,699) INFO - qlib.Initialization - [config.py:416] - default_conf: client.\n",
      "[36736:MainThread](2024-07-31 18:01:05,255) INFO - qlib.Initialization - [__init__.py:74] - qlib successfully initialized based on client settings.\n",
      "[36736:MainThread](2024-07-31 18:01:05,257) INFO - qlib.Initialization - [__init__.py:76] - data_path={'__DEFAULT_FREQ': WindowsPath('C:/Users/liush/.qlib/qlib_data/cn_data_rolling')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.04110304208418048, 0.3091372140997289)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T10:07:46.504871Z",
     "start_time": "2024-07-31T10:07:46.493545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import column_or_1d\n",
    "import lightgbm as lgb\n",
    "\n",
    "def train_lgbm(exprs: List[Expression], pretrained: Booster, target_value: Tensor) -> Booster:\n",
    "    n_splits = 2\n",
    "    X = torch.stack([_calc_alpha(expr) for expr in exprs], dim=-1).cpu().numpy()\n",
    "    X = X.reshape(-1, X.shape[-1])\n",
    "    y = column_or_1d(target_value.cpu().numpy().reshape(-1, 1))\n",
    "\n",
    "    threshold = 3\n",
    "\n",
    "    X = np.where(X > threshold, threshold, X)\n",
    "    X = np.where(X < -threshold, -threshold, X)\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    best_model = None\n",
    "    best_score = float('inf')\n",
    "\n",
    "    for train_index, valid_index in kf.split(X):\n",
    "        X_train, X_valid = X[train_index], X[valid_index]\n",
    "        y_train, y_valid = y[train_index], y[valid_index]\n",
    "        \n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "\n",
    "\n",
    "        params = {\n",
    "            'objective': 'regression',  # 根据你的实际任务调整\n",
    "            'learning_rate': 0.01,\n",
    "            'num_leaves': 31,\n",
    "            'metric': 'l1'  # 根据你的实际任务调整\n",
    "        }\n",
    "            \n",
    "        # 继续训练模型\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            num_boost_round=100,  # 继续训练的迭代次数\n",
    "            valid_sets=[valid_data],\n",
    "            init_model=pretrained  # 传入之前训练好的模型\n",
    "        )\n",
    "\n",
    "        score = model.best_score['valid_0']['l1']\n",
    "        # 计算训练误差\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "\n",
    "        # 计算测试误差\n",
    "        y_test_pred = model.predict(X_valid)\n",
    "        test_rmse = mean_squared_error(y_valid, y_test_pred, squared=False)\n",
    "\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "        print(f'Train RMSE: {train_rmse}')\n",
    "        print(f'Test RMSE: {test_rmse}')\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "\n",
    "        best_model = model\n",
    "\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_model = model\n",
    "\n",
    "    return best_model"
   ],
   "id": "320a405ffe70c550",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T10:12:03.248438Z",
     "start_time": "2024-07-31T10:07:47.595842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "booster = train_lgbm(exprs, booster, calculator.target_value)\n",
    "print(test_ensemble(exprs, booster, calculator))"
   ],
   "id": "e54ecd64bd87c540",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.264147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51510\n",
      "[LightGBM] [Info] Number of data points in the train set: 558705, number of used features: 202\n",
      "[LightGBM] [Warning] Detected that num_threads changed during training (from 14 to 12), it may cause unexpected errors.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Train RMSE: 0.770786456530388\n",
      "Test RMSE: 0.7728961864060868\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.285636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51510\n",
      "[LightGBM] [Info] Number of data points in the train set: 558705, number of used features: 202\n",
      "[LightGBM] [Warning] Detected that num_threads changed during training (from 14 to 12), it may cause unexpected errors.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Train RMSE: 0.7703777354020531\n",
      "Test RMSE: 0.7747928378267063\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.238492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51510\n",
      "[LightGBM] [Info] Number of data points in the train set: 558706, number of used features: 202\n",
      "[LightGBM] [Warning] Detected that num_threads changed during training (from 14 to 12), it may cause unexpected errors.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Train RMSE: 0.7710394890368096\n",
      "Test RMSE: 0.7720847480992675\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51510\n",
      "[LightGBM] [Info] Number of data points in the train set: 558706, number of used features: 202\n",
      "[LightGBM] [Warning] Detected that num_threads changed during training (from 14 to 12), it may cause unexpected errors.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Train RMSE: 0.7716799581911299\n",
      "Test RMSE: 0.7691716540854621\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.259817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51510\n",
      "[LightGBM] [Info] Number of data points in the train set: 558706, number of used features: 202\n",
      "[LightGBM] [Warning] Detected that num_threads changed during training (from 14 to 12), it may cause unexpected errors.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Train RMSE: 0.7709033672737219\n",
      "Test RMSE: 0.7742295378629546\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(0.10099588101975067, 0.7814813177402851)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T10:16:56.183283Z",
     "start_time": "2024-07-31T10:16:56.153187Z"
    }
   },
   "cell_type": "code",
   "source": "booster.save_model('model/boostered.txt')",
   "id": "dd64dd2c32949c37",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x1d9f00c6af0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T10:18:53.744938Z",
     "start_time": "2024-07-31T10:18:53.705990Z"
    }
   },
   "cell_type": "code",
   "source": "booster.feature_importance()",
   "id": "2ef52860421e528",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 90,  53,  21,  44,  14, 106, 188,  23,  74,  25,  12,  16,  17,\n",
       "        69,   3,  12,  18,  98,  15,  67,   2,  15,  15,  14,   9,  13,\n",
       "        25,  29,  83,  67,  13,  19,   4,  26,  10,  36,  24,  23,  13,\n",
       "        17,  51,  10,   6,  25,   8,  11,   7,  43,  34,   6,   6,  57,\n",
       "         8,  38,  17,   8,   9,  12,  30,  14,   3,  20,  19,  13,   3,\n",
       "        16,  50,   7,   6,  60,   1,  39,  26,  19, 184,  25,  12,   9,\n",
       "        89,  90,  27,  17,   6,  17,  13,   4,  27,  26,  57,   8,  38,\n",
       "        13,  56,  27,  11,  95,   9,  22,  27,   9,  37, 116,  10,  10,\n",
       "        30,  42,   9,   6,  18,  76,  19,  16,  51,  37,  28, 102,  12,\n",
       "        51,  12,   6,   7,  77,  75,   9,  17,  17,  41,  47,   4,  12,\n",
       "        38,   9,  14,  24,  18,  25,  94,  29,  90,  64,  16, 132,  26,\n",
       "         9,  11,  15,  24,  41,  88,  12,  19,  39,  63,  10,  75,  26,\n",
       "        10,  77,  10,   4,  18,   5,  36,  33, 101,   9,  20,   2,  35,\n",
       "         6,   1,   6,   9,   5,  59,  18,  11,  15,  38,   6,   9, 198,\n",
       "         7,   4,  12,   1,   3,   2,   5,  10,  26,  34,  28,   1,  16,\n",
       "        18,   6,   9,   1,   4,  17,  18])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "241862aeb60a23de"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

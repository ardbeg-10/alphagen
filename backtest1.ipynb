{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T05:05:54.345867Z",
     "start_time": "2024-08-01T05:05:48.357369Z"
    }
   },
   "source": [
    "from typing import Optional, TypeVar, Callable, Optional, Tuple\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from qlib.backtest import backtest, executor as exec\n",
    "from qlib.contrib.evaluate import risk_analysis\n",
    "from qlib.contrib.report.analysis_position import report_graph\n",
    "from alphagen.data.expression import *\n",
    "\n",
    "from alphagen_qlib.stock_data import StockData\n",
    "from alphagen_generic.features import *\n",
    "from alphagen_qlib.strategy import TopKSwapNStrategy\n",
    "# from alphagen_qlib.neutral_strategy import MarketNeutralStrategy\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import json\n",
    "\n",
    "_T = TypeVar(\"_T\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "d50b6d62-7763-49ad-9005-d66e9c34c0fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T05:05:54.361853Z",
     "start_time": "2024-08-01T05:05:54.346852Z"
    }
   },
   "source": [
    "def _create_parents(path: str) -> None:\n",
    "    dir = os.path.dirname(path)\n",
    "    if dir != \"\":\n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def write_all_text(path: str, text: str) -> None:\n",
    "    _create_parents(path)\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "\n",
    "def dump_pickle(path: str,\n",
    "                factory: Callable[[], _T],\n",
    "                invalidate_cache: bool = False) -> Optional[_T]:\n",
    "    if invalidate_cache or not os.path.exists(path):\n",
    "        _create_parents(path)\n",
    "        obj = factory()\n",
    "        with open(path, \"wb\") as f:\n",
    "            pickle.dump(obj, f)\n",
    "        return obj\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "3919423ff75d6080",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T05:05:54.377487Z",
     "start_time": "2024-08-01T05:05:54.363138Z"
    }
   },
   "source": [
    "class BacktestResult(dict):\n",
    "    sharpe: float\n",
    "    annual_return: float\n",
    "    max_drawdown: float\n",
    "    information_ratio: float\n",
    "    annual_excess_return: float\n",
    "    excess_max_drawdown: float\n",
    "\n",
    "\n",
    "class QlibBacktest:\n",
    "    def __init__(\n",
    "        self,\n",
    "        benchmark: str = \"SH000905\",\n",
    "        top_k: int = 50,\n",
    "        n_drop: Optional[int] = None,\n",
    "        deal: str = \"close\",\n",
    "        open_cost: float = 0.0015,\n",
    "        close_cost: float = 0.0015,\n",
    "        min_cost: float = 5,\n",
    "    ):\n",
    "        self._benchmark = benchmark\n",
    "        self._top_k = top_k\n",
    "        self._n_drop = n_drop if n_drop is not None else top_k\n",
    "        self._deal_price = deal\n",
    "        self._open_cost = open_cost\n",
    "        self._close_cost = close_cost\n",
    "        self._min_cost = min_cost\n",
    "\n",
    "    def run(\n",
    "        self,\n",
    "        prediction: pd.Series,\n",
    "        output_prefix: Optional[str] = '~/backtest',\n",
    "        return_report: bool = False\n",
    "    ) -> BacktestResult:\n",
    "        prediction = prediction.sort_index()\n",
    "        index: pd.MultiIndex = prediction.index.remove_unused_levels()  # type: ignore\n",
    "        dates = index.levels[0]\n",
    "\n",
    "        def backtest_impl(last: int = -1):\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                strategy=TopKSwapNStrategy(\n",
    "                    K=self._top_k,\n",
    "                    n_swap=self._top_k,\n",
    "                    signal=prediction,\n",
    "                    min_hold_days=1,\n",
    "                    only_tradable=True,\n",
    "                )\n",
    "                executor=exec.SimulatorExecutor(\n",
    "                    time_per_step=\"day\",\n",
    "                    generate_portfolio_metrics=True\n",
    "                )\n",
    "                return backtest(\n",
    "                    strategy=strategy,\n",
    "                    executor=executor,\n",
    "                    start_time=dates[0],\n",
    "                    end_time=dates[last],\n",
    "                    account=100_000_000,\n",
    "                    benchmark=self._benchmark,\n",
    "                    exchange_kwargs={\n",
    "                        \"limit_threshold\": 0.095,\n",
    "                        \"deal_price\": self._deal_price,\n",
    "                        \"open_cost\": self._open_cost,\n",
    "                        \"close_cost\": self._close_cost,\n",
    "                        \"min_cost\": self._min_cost,\n",
    "                    }\n",
    "                )[0]\n",
    "\n",
    "        try:\n",
    "            portfolio_metric = backtest_impl()\n",
    "        except IndexError:\n",
    "            print(\"Cannot backtest till the last day, trying again with one less day\")\n",
    "            portfolio_metric = backtest_impl(-2)\n",
    "\n",
    "        report, _ = portfolio_metric[\"1day\"]    # type: ignore\n",
    "        result = self._analyze_report(report)\n",
    "        \n",
    "        try: \n",
    "            report_graph(report)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to generate report graph: {e}\")\n",
    "\n",
    "        if output_prefix is not None:\n",
    "            dump_pickle(output_prefix + \"/report.pkl\", lambda: report, True)\n",
    "            # dump_pickle(output_prefix + \"/graph.pkl\", lambda: graph, True)\n",
    "            result_json = json.dumps(result, indent=4)\n",
    "            write_all_text(output_prefix + \"/result.json\", result_json)\n",
    "\n",
    "        print(report)\n",
    "        print(result)\n",
    "        return report if return_report else result\n",
    "\n",
    "    def _analyze_report(self, report: pd.DataFrame) -> BacktestResult:\n",
    "        excess = risk_analysis(report[\"return\"] - report[\"bench\"] - report[\"cost\"])[\"risk\"]\n",
    "        returns = risk_analysis(report[\"return\"] - report[\"cost\"])[\"risk\"]\n",
    "\n",
    "        def loc(series: pd.Series, field: str) -> float:\n",
    "            return series.loc[field]    # type: ignore\n",
    "\n",
    "        return BacktestResult(\n",
    "            sharpe=loc(returns, \"information_ratio\"),\n",
    "            annual_return=loc(returns, \"annualized_return\"),\n",
    "            max_drawdown=loc(returns, \"max_drawdown\"),\n",
    "            information_ratio=loc(excess, \"information_ratio\"),\n",
    "            annual_excess_return=loc(excess, \"annualized_return\"),\n",
    "            excess_max_drawdown=loc(excess, \"max_drawdown\"),\n",
    "        )\n",
    "    \n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "6b8daf26b3e84e8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T05:05:54.392741Z",
     "start_time": "2024-08-01T05:05:54.379496Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from lightgbm import Booster\n",
    "from alphagen_qlib.utils import load_alpha_pool_by_path, load_dt_model_by_path\n",
    "from alphagen_qlib.calculator import QLibStockDataCalculator\n",
    "from alphagen.utils.pytorch_utils import normalize_by_day\n",
    "from alphagen.data.calculator import AlphaCalculator\n",
    "from alphagen.utils.correlation import batch_pearsonr, batch_spearmanr"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "9b91162a-2d16-493f-81cd-1428b19b4086",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T05:05:54.408744Z",
     "start_time": "2024-08-01T05:05:54.393726Z"
    }
   },
   "source": [
    "def make_ensemble_alpha(exprs: List[Expression], model: Booster) -> Tensor:\n",
    "    n = len(exprs)\n",
    "    return torch.from_numpy(predict(model, exprs)).to(data.device)\n",
    "\n",
    "def predict(model: Booster, exprs: List[Expression]) -> np.ndarray:\n",
    "    X = torch.stack([_calc_alpha(expr) for expr in exprs], dim=-1).cpu().numpy()\n",
    "    X = X.reshape(-1, X.shape[-1])\n",
    "    val = model.predict(X)\n",
    "    return unstack(val)\n",
    "\n",
    "def unstack(value: np.ndarray) -> np.ndarray:\n",
    "    return value.reshape(data.n_days, data.n_stocks)\n",
    "\n",
    "def _calc_alpha(expr: Expression) -> Tensor:\n",
    "    return normalize_by_day(expr.evaluate(data))\n",
    "\n",
    "def _calc_ICs(value1: Tensor, value2: Tensor) -> Tensor:\n",
    "    return batch_pearsonr(value1, value2)\n",
    "\n",
    "def _calc_IC(value1: Tensor, value2: Tensor) -> float:\n",
    "    return batch_pearsonr(value1, value2).mean().item()\n",
    "\n",
    "def _calc_IR(value1: Tensor, value2: Tensor) -> float:\n",
    "    ICs = _calc_ICs(value1, value2)\n",
    "    IC_mean = ICs.mean().item()\n",
    "    IC_std = ICs.std().item()\n",
    "    epsilon = 1e-10  # 防止除以零的小值\n",
    "    IR = IC_mean / (IC_std - epsilon)\n",
    "    return IR\n",
    "\n",
    "def test_ensemble(exprs: List[Expression], model: Booster, calculator: AlphaCalculator) -> Tuple[float, float]:\n",
    "    return calc_pool_all_ret(exprs, calculator.target_value, model)\n",
    "\n",
    "def calc_pool_all_ret(exprs: List[Expression], target: Tensor, model: Booster) -> Tuple[float, float]:\n",
    "    with torch.no_grad():\n",
    "        ensemble_value = make_ensemble_alpha(exprs, model)\n",
    "        return _calc_IC(ensemble_value, target), _calc_IR(ensemble_value, target)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "cae5ff5b-b0cb-4ec9-bc24-1ca1cde37f10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T05:05:54.424388Z",
     "start_time": "2024-08-01T05:05:54.410745Z"
    }
   },
   "source": [
    "# from pprint import pprint\n",
    "\n",
    "# import qlib\n",
    "# import pandas as pd\n",
    "# from qlib.utils.time import Freq\n",
    "# from qlib.utils import flatten_dict\n",
    "# from qlib.contrib.evaluate import backtest_daily\n",
    "# from qlib.contrib.evaluate import risk_analysis\n",
    "# from qlib.contrib.strategy import TopkDropoutStrategy\n",
    "\n",
    "# POOL_PATH = '/root/autodl-tmp/save/new_csi500_65_1_20240730151748/10240_steps_pool.json'\n",
    "# DT_PATH = '/root/autodl-tmp/save/new_csi500_65_1_20240730151748/10240_steps_dt.txt'\n",
    "\n",
    "# data = StockData(instrument='csi500',\n",
    "#                  start_time='2024-04-01',\n",
    "#                  end_time='2024-06-01')\n",
    "\n",
    "# close = Feature(FeatureType.CLOSE)\n",
    "# target = Ref(close, -5) / close - 1\n",
    "\n",
    "# calculator = QLibStockDataCalculator(data=data, target=target)\n",
    "# exprs, _ = load_alpha_pool_by_path(POOL_PATH)\n",
    "# booster = load_dt_model_by_path(DT_PATH)\n",
    "\n",
    "# ensemble_alpha = make_ensemble_alpha(exprs, booster)\n",
    "# df = data.make_dataframe(ensemble_alpha)\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "99865398-05a0-4a21-bda7-70814dd4add1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T05:05:54.439918Z",
     "start_time": "2024-08-01T05:05:54.426368Z"
    }
   },
   "source": [
    "# # init qlib\n",
    "# CSI300_BENCH = \"SH000905\"\n",
    "# qlib.init(provider_uri='~/.qlib/cn_data_rolling')\n",
    "\n",
    "# STRATEGY_CONFIG = {\n",
    "#     \"topk\": 50,\n",
    "#     \"n_drop\": 0,\n",
    "#     # pred_score, pd.Series\n",
    "#     \"signal\": df['0'],\n",
    "# }\n",
    "\n",
    "# strategy_obj = TopkDropoutStrategy(**STRATEGY_CONFIG)\n",
    "# report_normal, positions_normal = backtest_daily(\n",
    "#     start_time=\"2024-04-01\", end_time=\"2024-06-01\", strategy=strategy_obj\n",
    "# )\n",
    "# analysis = dict()\n",
    "# # default frequency will be daily (i.e. \"day\")\n",
    "# analysis[\"excess_return_without_cost\"] = risk_analysis(report_normal[\"return\"] - report_normal[\"bench\"])\n",
    "# analysis[\"excess_return_with_cost\"] = risk_analysis(report_normal[\"return\"] - report_normal[\"bench\"] - report_normal[\"cost\"])\n",
    "\n",
    "# analysis_df = pd.concat(analysis)  # type: pd.DataFrame\n",
    "# pprint(analysis_df)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "33b8438a-c85f-4a08-bbf6-e4eb6694c1d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T05:05:54.454718Z",
     "start_time": "2024-08-01T05:05:54.440901Z"
    }
   },
   "source": [
    "# from pprint import pprint\n",
    "\n",
    "# import qlib\n",
    "# import pandas as pd\n",
    "# from qlib.utils.time import Freq\n",
    "# from qlib.utils import flatten_dict\n",
    "# from qlib.backtest import backtest, executor\n",
    "# from qlib.contrib.evaluate import risk_analysis\n",
    "# from qlib.contrib.strategy import TopkDropoutStrategy\n",
    "\n",
    "# # init qlib\n",
    "# qlib.init(provider_uri='~/.qlib/cn_data_rolling')\n",
    "\n",
    "# CSI500_BENCH = \"SH000905\"\n",
    "# # Benchmark is for calculating the excess return of your strategy.\n",
    "# # Its data format will be like **ONE normal instrument**.\n",
    "# # For example, you can query its data with the code below\n",
    "# # `D.features([\"SH000300\"], [\"$close\"], start_time='2010-01-01', end_time='2017-12-31', freq='day')`\n",
    "# # It is different from the argument `market`, which indicates a universe of stocks (e.g. **A SET** of stocks like csi300)\n",
    "# # For example, you can query all data from a stock market with the code below.\n",
    "# # ` D.features(D.instruments(market='csi300'), [\"$close\"], start_time='2010-01-01', end_time='2017-12-31', freq='day')`\n",
    "\n",
    "# FREQ = \"day\"\n",
    "# STRATEGY_CONFIG = {\n",
    "#     \"topk\": 50,\n",
    "#     \"n_drop\": 5,\n",
    "#     # pred_score, pd.Series\n",
    "#     \"signal\": df['0'],\n",
    "# }\n",
    "\n",
    "# EXECUTOR_CONFIG = {\n",
    "#     \"time_per_step\": \"month\",\n",
    "#     \"generate_portfolio_metrics\": True,\n",
    "# }\n",
    "\n",
    "# backtest_config = {\n",
    "#     \"start_time\": \"2024-04-01\",\n",
    "#     \"end_time\": \"2024-06-01\",\n",
    "#     \"account\": 100000000,\n",
    "#     \"benchmark\": CSI500_BENCH,\n",
    "#     \"exchange_kwargs\": {\n",
    "#         \"freq\": FREQ,\n",
    "#         \"limit_threshold\": 0.095,\n",
    "#         \"deal_price\": \"close\",\n",
    "#         \"open_cost\": 0.0005,\n",
    "#         \"close_cost\": 0.0015,\n",
    "#         \"min_cost\": 5,\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# # strategy object\n",
    "# strategy_obj = TopkDropoutStrategy(**STRATEGY_CONFIG)\n",
    "# # executor object\n",
    "# executor_obj = executor.SimulatorExecutor(**EXECUTOR_CONFIG)\n",
    "# # backtest\n",
    "# portfolio_metric_dict, indicator_dict = backtest(executor=executor_obj, strategy=strategy_obj, **backtest_config)\n",
    "# analysis_freq = \"{0}{1}\".format(*Freq.parse(FREQ))\n",
    "# # backtest info\n",
    "# report_normal, positions_normal = portfolio_metric_dict.get(analysis_freq)\n",
    "\n",
    "# # analysis\n",
    "# analysis = dict()\n",
    "# analysis[\"excess_return_without_cost\"] = risk_analysis(\n",
    "#     report_normal[\"return\"] - report_normal[\"bench\"], freq=analysis_freq\n",
    "# )\n",
    "# analysis[\"excess_return_with_cost\"] = risk_analysis(\n",
    "#     report_normal[\"return\"] - report_normal[\"bench\"] - report_normal[\"cost\"], freq=analysis_freq\n",
    "# )\n",
    "\n",
    "# analysis_df = pd.concat(analysis)  # type: pd.DataFrame\n",
    "# # log metrics\n",
    "# analysis_dict = flatten_dict(analysis_df[\"risk\"].unstack().T.to_dict())\n",
    "# # print out results\n",
    "# pprint(f\"The following are analysis results of benchmark return({analysis_freq}).\")\n",
    "# pprint(risk_analysis(report_normal[\"bench\"], freq=analysis_freq))\n",
    "# pprint(f\"The following are analysis results of the excess return without cost({analysis_freq}).\")\n",
    "# pprint(analysis[\"excess_return_without_cost\"])\n",
    "# pprint(f\"The following are analysis results of the excess return with cost({analysis_freq}).\")\n",
    "# pprint(analysis[\"excess_return_with_cost\"])"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "c8614105-2163-4a0d-a1ab-357efef5ab3c",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-08-01T05:06:12.352475Z",
     "start_time": "2024-08-01T05:05:54.455719Z"
    }
   },
   "source": [
    "POOL_PATH = '/root/alphagen/model/63488_steps_pool.json'\n",
    "DT_PATH = '/root/alphagen/model/63488_steps_dt.txt'\n",
    "\n",
    "qlib_backtest = QlibBacktest()\n",
    "\n",
    "data = StockData(instrument='csi500',\n",
    "                 start_time='2020-04-01',\n",
    "                 end_time='2022-06-01')\n",
    "\n",
    "close = Feature(FeatureType.CLOSE)\n",
    "target = Ref(close, -1) / close - 1\n",
    "\n",
    "calculator = QLibStockDataCalculator(data=data, target=target)\n",
    "exprs, _ = load_alpha_pool_by_path(POOL_PATH)\n",
    "booster = load_dt_model_by_path(DT_PATH)\n",
    "\n",
    "ensemble_alpha = make_ensemble_alpha(exprs, booster)\n",
    "df = data.make_dataframe(ensemble_alpha)\n",
    "\n",
    "print(test_ensemble(exprs, booster, calculator))\n",
    "\n",
    "qlib_backtest.run(df)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[28988:MainThread](2024-08-01 13:05:54,462) INFO - qlib.Initialization - [config.py:416] - default_conf: client.\n",
      "[28988:MainThread](2024-08-01 13:05:54,927) INFO - qlib.Initialization - [__init__.py:74] - qlib successfully initialized based on client settings.\n",
      "[28988:MainThread](2024-08-01 13:05:54,928) INFO - qlib.Initialization - [__init__.py:76] - data_path={'__DEFAULT_FREQ': WindowsPath('C:/Users/liush/.qlib/qlib_data/cn_data_rolling')}\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/root/alphagen/model/63488_steps_pool.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 14\u001B[0m\n\u001B[0;32m     11\u001B[0m target \u001B[38;5;241m=\u001B[39m Ref(close, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m/\u001B[39m close \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     13\u001B[0m calculator \u001B[38;5;241m=\u001B[39m QLibStockDataCalculator(data\u001B[38;5;241m=\u001B[39mdata, target\u001B[38;5;241m=\u001B[39mtarget)\n\u001B[1;32m---> 14\u001B[0m exprs, _ \u001B[38;5;241m=\u001B[39m \u001B[43mload_alpha_pool_by_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43mPOOL_PATH\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m booster \u001B[38;5;241m=\u001B[39m load_dt_model_by_path(DT_PATH)\n\u001B[0;32m     17\u001B[0m ensemble_alpha \u001B[38;5;241m=\u001B[39m make_ensemble_alpha(exprs, booster)\n",
      "File \u001B[1;32m~\\Downloads\\量化研究\\alphagen\\alphagen_qlib\\utils.py:37\u001B[0m, in \u001B[0;36mload_alpha_pool_by_path\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_alpha_pool_by_path\u001B[39m(path: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[List[Expression], List[\u001B[38;5;28mfloat\u001B[39m]]:\n\u001B[1;32m---> 37\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m     38\u001B[0m         raw \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(f)\n\u001B[0;32m     39\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m load_alpha_pool(raw)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/root/alphagen/model/63488_steps_pool.json'"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "684ee6dd-0d1d-415d-9bff-a3fbd5b9d234",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
